{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDS_Homework_Taglieri_1890945.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wAEgygyPfO7b",
        "Rl9dZ3HambSz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdnnRxTNdyW1"
      },
      "source": [
        "# Neural Networks for Data Science Applications\n",
        "## Mid-term Homework: Implementing a custom activation function\n",
        "\n",
        "**Name**: *Alessandro Taglieri*\n",
        "\n",
        "**Matricola**: *1890945*\n",
        "\n",
        "Send the completed notebook before 03/12/2020 back to **simone.scardapane@uniroma1.it** with the object \"[NNDS] Homework_1_\\<id\\>\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEr8qV6-nMuL"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAEgygyPfO7b"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "The **exponential linear unit** (ELU) is an activation function defined as [1]:\n",
        "\n",
        "$$\n",
        "\\phi(x) =\n",
        "\\Biggl\\{ \n",
        "\\begin{align} \n",
        "x & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
        "\\alpha \\left(\\exp\\left(x\\right)- 1\\right) & \\;\\; \\text{ otherwise } \n",
        "\\end{align}\n",
        "\\Bigr.\n",
        "\\,,\n",
        "$$\n",
        "\n",
        "where $\\alpha$ is a hyper-parameter. The function is implemented in `tf.keras.layers.ELU` (see the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ELU)).\n",
        "\n",
        "The **parametric ELU** (PELU) extends the ELU activation function as [2]:\n",
        "\n",
        "$$\n",
        "\\phi(x) =\n",
        "\\Biggl\\{ \n",
        "\\begin{align} \n",
        "\\frac{\\alpha}{\\beta}x & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
        "\\alpha \\left(\\exp\\Bigl(\\frac{x}{\\beta}\\Bigr)- 1\\right) & \\;\\; \\text{ otherwise } \n",
        "\\end{align}\n",
        "\\Bigr.\n",
        "\\,,\n",
        "$$\n",
        "\n",
        "where the major difference is that $\\alpha,\\beta > 0$ are *trainable* parameters, i.e., a pair of $(\\alpha, \\beta)$ values is trained for each unit in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u4aF6Z4maHd"
      },
      "source": [
        "### Exercise 1: implement the PELU\n",
        "\n",
        "In TensorFlow, it is possible to implement new layers by subclassing `tf.keras.layers.Layer`:\n",
        "\n",
        "+ [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n",
        "+ [Custom layers](https://www.tensorflow.org/tutorials/customization/custom_layers)\n",
        "+ [tf.keras.layers.Layer (documentation)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)\n",
        "\n",
        "**Exercise 1**: *After carefully reading the guides*, complete the following implementation of the PELU activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO7YzHjjj7Z_"
      },
      "source": [
        "from tensorflow.keras.constraints import NonNeg\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def greater_than_zero(value):\n",
        "\teps = 1e-9\n",
        "\treturn eps + K.pow(value, 2)\n",
        " \n",
        "class PELU(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units=32):\n",
        "        super(PELU, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape=_):\n",
        "\n",
        "        param_init = tf.random_uniform_initializer(minval=0.1, maxval=1)\n",
        "        self.params = self.add_weight(\n",
        "            shape = (self.units, 2), \n",
        "            initializer = param_init,\n",
        "            constraint = NonNeg(), \n",
        "            dtype='float32', \n",
        "            trainable = True\n",
        "            \n",
        "        )\n",
        "        \n",
        "\n",
        "    def call(self, inputs):\n",
        "        alpha, beta = self.params[:,0], self.params[:,1]\n",
        "        first = greater_than_zero(alpha)/greater_than_zero(beta)*inputs*tf.cast(inputs>=0, dtype='float32')\n",
        "        two = greater_than_zero(alpha)*(K.exp(inputs/greater_than_zero(beta)*tf.cast(inputs<0, dtype='float32'))-1)\n",
        "        \n",
        "        return first + two\n",
        "        \n",
        "      "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8MEZxqbn8vs"
      },
      "source": [
        "**Hints for a correct implementation**:\n",
        "\n",
        "1. The layer (probably) requires two sets of trainable variables, whose shape depends on the number of units.\n",
        "2. From the definition of the PELU, $\\alpha, \\beta$ are required to be positive in order to ensure differentiability. The simplest way to handle this is to use a [constraint callable](https://www.tensorflow.org/api_docs/python/tf/keras/constraints) when creating the weight (see also the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) for `add_weight`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QY0TfCxo9yd"
      },
      "source": [
        "### Exercise 2: some preliminary tests\n",
        "\n",
        "To evaluate your implementation, let us start by creating a single PELU function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFNFXarBe8DV"
      },
      "source": [
        "pelu = PELU(units=1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWY76mEepSgj"
      },
      "source": [
        "**Exercise 2.1**: plot the function using the skeleton code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdK0CyscfDtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "0d69b4b1-0e67-4e6c-8cdd-b6e624c0ee8e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x_range = tf.linspace(-5, 5, 200) # An equispaced grid of 200 points in [-5, +5]\n",
        "y = pelu(x_range.numpy())\n",
        "\n",
        "plt.plot(x_range.numpy(), y.numpy())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer pelu_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4e98185630>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyGIlR_aqayc"
      },
      "source": [
        "The derivative of a PELU function with respect to the $\\alpha$ parameter is given by [2]:\n",
        "\n",
        "$$\n",
        "\\frac{d\\phi(x)}{d\\alpha} =\n",
        "\\Biggl\\{ \n",
        "\\begin{align} \n",
        "\\frac{x}{\\beta} & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
        " \\left(\\exp\\Bigl(\\frac{x}{\\beta}\\Bigr)- 1\\right) & \\;\\; \\text{ otherwise } \n",
        "\\end{align}\n",
        "\\Bigr.\n",
        "\\,,\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnvkoRVAqwg1"
      },
      "source": [
        "**Exercise 2.2**: using a `tf.GradientTape` object, compute the derivative above using automatic differentiation, and check its correctness up to a certain numerical precision.\n",
        "\n",
        "**Hints for a correct implementation**:\n",
        "\n",
        "1. `tf.GradientTape` allows to compute the derivative *at a single point x*. If you prefer to avoid a loop over all possible points, consider using the `jacobian` function to obtain them in a single pass ([Advanced Automatic Differentiation](https://www.tensorflow.org/guide/advanced_autodiff)).\n",
        "2. Given two tensors x and y, a simple way to compute elementwise similarity up to a certain precision (e.g., $10^{-4}$), is given by `tf.reduce_all(tf.abs(x - y) < 1e-4)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KXmo6GXtAnX"
      },
      "source": [
        "# compute derivative of a pelu function with alpha given by the formula[2] and respect to beta\n",
        "def gradient(x, params):\n",
        "    alpha, beta = params[:,0], params[:,1]\n",
        "    \n",
        "    alpha_gr = tf.where(x>=0, x/beta, tf.exp(x/beta)-1)\n",
        "    beta_gr = tf.where(x>=0, -alpha/beta**2*x, -alpha*x/beta**2*tf.exp(x/beta))\n",
        "    \n",
        "    return tf.stack([alpha_gr, beta_gr], axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYPezXFi84W"
      },
      "source": [
        "#compute gradient and we'll have in output two tensor: gradient and tf_gradient that we use to computee their elemntwise similiarity\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    #tape.watch(x_range)\n",
        "    pelu_res = pelu(x_range)\n",
        "\n",
        "\n",
        "grad = tape.jacobian(pelu_res, pelu.params)\n",
        "\n",
        "tf_gradient = tf.reshape(grad, shape=(-1, 2))\n",
        "gradient = gradient(tf.cast(x_range, tf.float32), pelu.params)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTHw6LIjt2gz",
        "outputId": "47f82cdb-d41b-4efc-f66d-42af30106a07"
      },
      "source": [
        "#compute elementwise similarity up to a certain precision (e.g.,  (10)^−4 )\n",
        "tf.reduce_all(tf.abs(tf_gradient - gradient) < 1e-4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKw193iR95rB"
      },
      "source": [
        "**Exercise 2.3 (optional)**: try the same for the $\\beta$ parameter (you can check the analytical formula for the gradient in the original paper [2]). **Careful**: the equation in the original paper has a missing $h$ (thanks to Davide Aureli and Federico Siciliano for spotting this). See [the correct derivation](https://www.wolframalpha.com/input/?i=d%28a*%28exp%28h%2Fb%29-1%29%29%2Fdb) on Wolfram Alpha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yjnVl6Ysm7F"
      },
      "source": [
        "### Exercise 3: PELU in practice\n",
        "\n",
        "Consider a simple model built with the PELU activation function, as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF5S67DDs7xr"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#sequential model with Pelu\n",
        "model = tf.keras.Sequential(layers=[\n",
        "      tf.keras.layers.Dense(50),\n",
        "      PELU(50),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvVbeTDwtdbu"
      },
      "source": [
        "**Exercise 3**: load any classification dataset, and train the model above (using either a custom training loop or `model.fit(...)`). Additionally, compare with a standard ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Z7T0t01AD6"
      },
      "source": [
        "#we use the mnist dataset to fit and test our moddel. You can find this ddataset from the sample_data\n",
        "import pandas as pd\n",
        "train = pd.read_csv('/content/sample_data/mnist_train_small.csv', header=None)\n",
        "X_tr = train.iloc[:, 1:].values.astype('float32')\n",
        "y_tr = train.iloc[:, 0].values.reshape(-1,1).astype('float32')\n",
        "test = pd.read_csv('/content/sample_data/mnist_test.csv', header=None)\n",
        "X_tst = test.iloc[:, 1:].values.astype('float32')\n",
        "y_tst = test.iloc[:, 0].values.reshape(-1,1).astype('float32')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRAK00XU02zU"
      },
      "source": [
        "#get train_dataset and test_dataset to use in the fit/test\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_tr, y_tr))\n",
        "train_dataset = train_dataset.shuffle(1000).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_tst, y_tst)).batch(32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxoAm8LS-JDD"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "#define measures that we use in the compile function\n",
        "sgd = optimizers.SGD(learning_rate=1e-3)\n",
        "cross_entropy = losses.SparseCategoricalCrossentropy()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u1IZuTx-SRh",
        "outputId": "c6672509-aade-46d4-a6ef-4daea24647ba"
      },
      "source": [
        "from time import time\n",
        "#calculate time and other paramteter  to define performances of the model. This is needed to compare model with pelu with model with relu\n",
        "model.compile(optimizer=sgd,\n",
        "              loss=cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time()\n",
        "history_fit_pelu = model.fit(train_dataset, epochs=10)\n",
        "pelu_fit_time = time() - start_time\n",
        "\n",
        "start_time = time()\n",
        "history_eval_pelu=model.evaluate(test_dataset)\n",
        "pelu_eval_time = time() - start_time"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 7.8304 - accuracy: 0.4430\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.7654 - accuracy: 0.7753\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.8371\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.8644\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.4137 - accuracy: 0.8817\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8931\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8992\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.9048\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.9093\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.9134\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.9030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgix6eVXKizd",
        "outputId": "9ca84eb9-b2bf-45d8-9005-743613022d12"
      },
      "source": [
        "#summary of the model with pelu\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "pelu_1 (PELU)                (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 39,860\n",
            "Trainable params: 39,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkb3cj9r7uUH"
      },
      "source": [
        "**Exercise 3.1**: Additionally, compare with a standard ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvE12JW2_FcF",
        "outputId": "4cf5ab99-d201-4fcc-e3af-d56a50c8eee4"
      },
      "source": [
        "#define model with Relu\n",
        "model_withRelu = Sequential(layers=[\n",
        "                           \n",
        "                           tf.keras.layers.Dense(50, activation='relu'),\n",
        "                           tf.keras.layers.Dense(11, activation='softmax')\n",
        "])\n",
        "#calculate time and other measures to get performances of this model during training and test\n",
        "model_withRelu.compile(optimizer=sgd,\n",
        "              loss=cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "start_time = time()\n",
        "history_fit_relu = model_withRelu.fit(train_dataset, epochs=10)\n",
        "relu_fit_time = time() - start_time\n",
        "\n",
        "start_time = time()\n",
        "history_eval_relu=model_withRelu.evaluate(test_dataset)\n",
        "relu_eval_time = time() - start_time\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 2.8565 - accuracy: 0.4701\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 1.1999 - accuracy: 0.6478\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.9925 - accuracy: 0.7295\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.8702 - accuracy: 0.7652\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.7554 - accuracy: 0.8026\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.8054\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.8142\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.8439\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.4405 - accuracy: 0.8697\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.8574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KELEf_3-J2cn",
        "outputId": "5b666237-8b72-487c-d8d2-dd45367f7783"
      },
      "source": [
        "#summary of the model with Relu\n",
        "model_withRelu.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                561       \n",
            "=================================================================\n",
            "Total params: 39,811\n",
            "Trainable params: 39,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dATmuwk9hSo"
      },
      "source": [
        "#simple function that calculate the average from the list\n",
        "def average(lst): \n",
        "    return sum(lst) / len(lst) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLVqKRj76VIZ"
      },
      "source": [
        "Compare two models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4ZqWAKr6SpE"
      },
      "source": [
        "#we put all measures that we obtained for both model in a dataframe. §in this way we can see the differences.\n",
        "data = [{'fit time': pelu_fit_time, 'eval time': pelu_eval_time, 'mean accuracy':average(history_fit_pelu.history['accuracy']),'mean loss':average(history_fit_pelu.history['loss']),'test_loss':history_eval_pelu[0],'test_acc':history_eval_pelu[1]},\n",
        "        {'fit time': relu_fit_time, 'eval time': relu_eval_time, 'mean accuracy':average(history_fit_relu.history['accuracy']),'mean loss':average(history_fit_relu.history['loss']),'test_loss':history_eval_relu[0],'test_acc':history_eval_relu[1]}\n",
        "        \n",
        "        ] \n",
        "performances = pd.DataFrame(data, index = ['Pelu','Relu']) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "jWTCnKQv8euS",
        "outputId": "a90c876b-d1c7-42c2-cc95-0ef2806cef6c"
      },
      "source": [
        "performances"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit time</th>\n",
              "      <th>eval time</th>\n",
              "      <th>mean accuracy</th>\n",
              "      <th>mean loss</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pelu</th>\n",
              "      <td>15.656992</td>\n",
              "      <td>0.776146</td>\n",
              "      <td>0.832125</td>\n",
              "      <td>1.172545</td>\n",
              "      <td>0.353307</td>\n",
              "      <td>0.9030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Relu</th>\n",
              "      <td>12.463586</td>\n",
              "      <td>0.606503</td>\n",
              "      <td>0.760770</td>\n",
              "      <td>0.946515</td>\n",
              "      <td>0.619113</td>\n",
              "      <td>0.8574</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fit time  eval time  mean accuracy  mean loss  test_loss  test_acc\n",
              "Pelu  15.656992   0.776146       0.832125   1.172545   0.353307    0.9030\n",
              "Relu  12.463586   0.606503       0.760770   0.946515   0.619113    0.8574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "OD_K6ogEZGLe",
        "outputId": "ebbb48e0-53d4-4e15-91e6-01a68ac2fe9a"
      },
      "source": [
        "#plot acuracy during training\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_fit_relu.history['accuracy'],label='relu')\n",
        "plt.plot(history_fit_pelu.history['accuracy'],label='pelu')\n",
        "plt.title('accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4e985bd390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv76cGntc_vM"
      },
      "source": [
        "**Considerations:**\n",
        "From the results we can see that the training time in PELU is higher than the fit time in Relu, because the computation for the PELU is higher. Than we can notice that the accuracy on the test set is higher than the accuracy that we had during evaluation in Relu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEjaJQT06jh9"
      },
      "source": [
        "TensorFlow has several options for saving or loading objects from the disk:\n",
        "\n",
        "1. [Save and load Keras models](https://www.tensorflow.org/guide/keras/save_and_serialize/)\n",
        "\n",
        "In many cases, custom classes require the implementation of a `get_config` / `from_config` functions to define the serialization behaviour.\n",
        "\n",
        "**Exercise 4 (optional)**: implement the `get_config` method and test your implementation as below (taken from the guide on saving and loading models)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voxx7kntvM0W"
      },
      "source": [
        "\n",
        "#model.save('pelu_model2')\n",
        "#del PELU # This is needed to remove any reference to PELU from memory\n",
        "#reloaded_model = tf.keras.models.load_model('pelu_model2')\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "838PN8xN0rIW"
      },
      "source": [
        "\n",
        "#print(\"Original model:\", model)\n",
        "#print(\"Loaded model:\", reloaded_model) # Observe that the object has been dynamically recreated in absence of the configuration options"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcpgUDLqDYcZ"
      },
      "source": [
        "Implementation af The PELU layer with get_config and from_config methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_qsU5TUDXhE"
      },
      "source": [
        "\n",
        "class PELU(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units=32):\n",
        "        super(PELU, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape=_):\n",
        "\n",
        "        param_init = tf.random_uniform_initializer(minval=0.1, maxval=1)\n",
        "        self.params = self.add_weight(\n",
        "            shape = (self.units, 2), \n",
        "            initializer = param_init, \n",
        "            trainable = True, \n",
        "            constraint = NonNeg(), \n",
        "            dtype='float32'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        alpha, beta = self.params[:,0], self.params[:,1]\n",
        "        pos = (greater_than_zero(alpha) / greater_than_zero(beta)) * tf.keras.activations.relu(inputs)\n",
        "        neg = greater_than_zero(alpha) * (K.exp((-tf.keras.activations.relu(-inputs)) / greater_than_zero(beta)) - 1)\n",
        "\n",
        "        return pos + neg\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PELU, self).get_config()\n",
        "      \n",
        "        return {\"units\": self.units}\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MUz6jJODjNC",
        "outputId": "235bfe70-7186-4eb7-c37f-20ef05903cc9"
      },
      "source": [
        "model = Sequential(layers=[\n",
        "                           tf.keras.layers.Dense(50),\n",
        "                           PELU(50),\n",
        "                           tf.keras.layers.Dense(11, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss=cross_entropy,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_dataset, epochs=10)\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 32996298.0000 - accuracy: 0.5658\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.7754 - accuracy: 0.7643\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.8367\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4625 - accuracy: 0.8664\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3994 - accuracy: 0.8830\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.3616 - accuracy: 0.8946\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.9039\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3152 - accuracy: 0.9080\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3006 - accuracy: 0.9125\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 2ms/step - loss: 0.2878 - accuracy: 0.9155\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3194 - accuracy: 0.9080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31942495703697205, 0.9079999923706055]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LiWV4zRFlkR",
        "outputId": "1f945cbb-f79e-431f-a062-070b5339e99e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "pelu_2 (PELU)                (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 11)                561       \n",
            "=================================================================\n",
            "Total params: 39,911\n",
            "Trainable params: 39,911\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NCk7o_IEDOk",
        "outputId": "048b708d-2da6-4e26-c01a-5a32126d7d34"
      },
      "source": [
        "config = model.get_config()\n",
        "new_model = tf.keras.Sequential.from_config(config, custom_objects={'PELU': PELU})\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "pelu_3 (PELU)                (None, 50)                100       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 11)                561       \n",
            "=================================================================\n",
            "Total params: 39,911\n",
            "Trainable params: 39,911\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl9dZ3HambSz"
      },
      "source": [
        "### References\n",
        "\n",
        "[1] Clevert, D.A., Unterthiner, T. and Hochreiter, S., 2015. [Fast and accurate deep network learning by exponential linear units (ELUs)](https://arxiv.org/abs/1511.07289). arXiv preprint arXiv:1511.07289.\n",
        "\n",
        "[2] Trottier, L., Gigu, P. and Chaib-draa, B., 2017. [Parametric exponential linear unit for deep convolutional neural networks](https://arxiv.org/abs/1605.09332). In 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA) (pp. 207-214). IEEE."
      ]
    }
  ]
}